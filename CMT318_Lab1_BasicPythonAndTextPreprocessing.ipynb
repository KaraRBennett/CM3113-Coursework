{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fa9fab83b39e0e8986fe51f4973a53c4",
          "grade": false,
          "grade_id": "cell-5a064f468649bd70",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Pbig2pBmi55s"
      },
      "source": [
        "# CMT318: Lab 1 - Python Fundamentals with Basic Text Processing (Autumn 2024)\n",
        "\n",
        "This notebook will serve to practice important Python concepts together with some basic preprocessing techniques. It has been extracted from [UW's CSE 447 / CSE M 547 Project 0](https://drive.google.com/file/d/1hiZ278EJCRp0iJntYO4c2tyZOzI4SLSP/view) originally written by [Kabir Ahuja](https://kabirahuja2431.github.io/).\n",
        "\n",
        "This noteboook covers basic python, such as:\n",
        "\n",
        "* Basic Data Types\n",
        "* Functions\n",
        "* Containers or Data structures: Lists, Dictionaries, Sets, Tuples,\n",
        "* Classes\n",
        "\n",
        "Three exercises related to text preprocessing are also included. Each exercise grows in complexity. Students who are already familiar with Python can go straight to the exercises if they prefer.\n",
        "\n",
        "**IMPORTANT: Save a copy of the notebook before working on it. You can also download it if you prefer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "980af17c21ada7fe25d31c635555cb3a",
          "grade": false,
          "grade_id": "cell-dc30aa59c9cc238c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "SueOJvhki55u"
      },
      "source": [
        "### Basic data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3e474a1b0ec4d300bfd3475303cd32b5",
          "grade": false,
          "grade_id": "cell-2458f5e84f665542",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XuFsfyDfi55u"
      },
      "source": [
        "#### Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "891a77ec73916dc04e2a247f13aeb6f3",
          "grade": false,
          "grade_id": "cell-00a9878a8c25762d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6zhzmszGi55u"
      },
      "source": [
        "Integers and floats work as you would expect from other languages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd9f07adbc6adbd95f91a7264ce3f423",
          "grade": false,
          "grade_id": "cell-85fbd24138b86dac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7l12UVT4i55u"
      },
      "outputs": [],
      "source": [
        "x = 3\n",
        "print(x, type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e884db29a64da9f1f6dc341d6fe2f643",
          "grade": false,
          "grade_id": "cell-6b28ee84781be258",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Cj0p4DX1i55u"
      },
      "outputs": [],
      "source": [
        "print(x + 1)  # Addition\n",
        "print(x - 1)  # Subtraction\n",
        "print(x * 2)  # Multiplication\n",
        "print(x**2)  # Exponentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d41e2c7e8ba32d92be0e9b2128b20c17",
          "grade": false,
          "grade_id": "cell-299ef7d17976ada9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zZAyfYiDi55u"
      },
      "outputs": [],
      "source": [
        "x += 1\n",
        "print(x)\n",
        "x *= 2\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eea207c8e420b00d6a046a63dfffa69e",
          "grade": false,
          "grade_id": "cell-3f6a29863eb2465d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5txrPcTki55v"
      },
      "source": [
        "Note that unlike many languages, Python does not have unary increment (x++) or decrement (x--) operators.\n",
        "\n",
        "Python also has built-in types for long integers and complex numbers; you can find all of the details in the [documentation](https://docs.python.org/3.7/library/stdtypes.html#numeric-types-int-float-long-complex)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zlXbhgKi55v"
      },
      "source": [
        "#### Booleans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-QM3SFKi55v"
      },
      "source": [
        "Python implements all of the usual operators for Boolean logic, but uses English words rather than symbols (`&&`, `||`, etc.):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4oZN83ki55v"
      },
      "outputs": [],
      "source": [
        "t, f = True, False\n",
        "print(type(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0IsIJvi55v"
      },
      "source": [
        "Now we let's look at the operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOC1lUDhi55v"
      },
      "outputs": [],
      "source": [
        "print(t and f)  # Logical AND;\n",
        "print(t or f)  # Logical OR;\n",
        "print(not t)  # Logical NOT;\n",
        "print(t != f)  # Logical XOR;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzsBLjZwi55v"
      },
      "source": [
        "#### Strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3wpWu_Di55v"
      },
      "outputs": [],
      "source": [
        "hello = \"hello\"  # String literals can use single quotes\n",
        "world = \"world\"  # or double quotes; it does not matter\n",
        "print(hello, len(hello))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfIOprZGi55v"
      },
      "outputs": [],
      "source": [
        "hw = hello + \" \" + world  # String concatenation\n",
        "print(hw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb4_U1w9i55w"
      },
      "outputs": [],
      "source": [
        "hw12 = f\"{hello} {world} {12}\"  # string formatting\n",
        "print(hw12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsc99bKei55w"
      },
      "source": [
        "String objects have a bunch of useful methods; for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW6LY7Ari55w"
      },
      "outputs": [],
      "source": [
        "s = \"hello\"\n",
        "print(s.capitalize())  # Capitalize a string\n",
        "print(s.upper())  # Convert a string to uppercase; prints \"HELLO\"\n",
        "print(s.rjust(7))  # Right-justify a string, padding with spaces\n",
        "print(s.center(7))  # Center a string, padding with spaces\n",
        "print(s.replace(\"l\", \"(ell)\"))  # Replace all instances of one substring with another\n",
        "print(\"  world \".strip())  # Strip leading and trailing whitespace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLdUewT-i55w"
      },
      "source": [
        "You can find a list of all string methods in the [documentation](https://docs.python.org/3.7/library/stdtypes.html#string-methods)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-3YIt9i55w"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGGHAVTsi55w"
      },
      "source": [
        "Python functions are defined using the `def` keyword. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BjpbSXXi55w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8389a2b-1e18-4f17-b5d9-afc2f5851b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n",
            "negative\n",
            "zero\n"
          ]
        }
      ],
      "source": [
        "def sign(x):\n",
        "    if x > 0:\n",
        "        return \"positive\"\n",
        "    elif x < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"zero\"\n",
        "\n",
        "\n",
        "print(sign(3))\n",
        "print(sign(-3))\n",
        "print(sign(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e2x8OfIi55w"
      },
      "source": [
        "We will often define functions to take optional keyword arguments, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLx1B3yli55w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d170b323-b3df-4819-a384-715be134585f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Bob!\n",
            "HELLO, FRED\n"
          ]
        }
      ],
      "source": [
        "def hello(name, loud=False):\n",
        "    if loud:\n",
        "        print(f\"HELLO, {name.upper()}\")\n",
        "    else:\n",
        "        print(f\"Hello, {name}!\")\n",
        "\n",
        "\n",
        "hello(\"Bob\")\n",
        "hello(\"Fred\", loud=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guryGLbzi55w"
      },
      "source": [
        "### Exercise 1: Basic Text Processing Using String Methods (Level 1)\n",
        "\n",
        "You will now use what we just learned to implement some basic text processing methods in Python. Text processing comes very much in handy when training machine learning models on natural language data. Since text processing is typically done before training of the models, it is also commonly referred to as *preprocessing*. For this exercise you will perform the following basic text processing steps:\n",
        "\n",
        "- convert the text to lower case\n",
        "- remove extra spaces (left trailing, right trailing, or in between the words)\n",
        "- remove punctuations\n",
        "\n",
        "Note that, while more advanced libraries like regular expressions (re) or natural language toolkit (NLTK) can also be used for implementing these methods, it is also straightforward to use string methods to carry out these basic operations. Try implementing these functions using string methods first, and then with functions from NLTK.\n",
        "\n",
        "**Important Note: Remove `raise NotImplementedError()` when you write your code in the functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bddf1fb4b24295539520efebb171ca69",
          "grade": false,
          "grade_id": "cell-243665322a6645a5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VymB-XPli55w"
      },
      "outputs": [],
      "source": [
        "def to_lowercase(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert a string to lowercase\n",
        "\n",
        "    E.g. \"Hello\" -> \"hello\"\n",
        "\n",
        "    Input:\n",
        "        - text: string\n",
        "    Output:\n",
        "        - string\n",
        "\n",
        "    \"\"\"\n",
        "    lowercase_text = None\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    return lowercase_text\n",
        "\n",
        "\n",
        "def remove_extra_spaces(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove extra spaces from a string.\n",
        "\n",
        "    E.g.: \"  This is a    string   \" -> \"This is a string\"\n",
        "\n",
        "    Input:\n",
        "        - text: string\n",
        "    Output:\n",
        "        - string\n",
        "\n",
        "    \"\"\"\n",
        "    text_without_extra_spaces = None\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return text_without_extra_spaces\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    \"\"\"\n",
        "    Remove punctuations from a string\n",
        "\n",
        "    E.g.: \"Hello! How are you?\" -> \"Hello How are you\"\n",
        "\n",
        "    Input:\n",
        "        - text: string\n",
        "    Output:\n",
        "        - string\n",
        "\n",
        "    \"\"\"\n",
        "    # we can get a list of punctuations from the string module\n",
        "    import string\n",
        "    punctuations = string.punctuation\n",
        "\n",
        "    text_without_punctuations = None\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return text_without_punctuations\n",
        "\n",
        "\n",
        "def text_processing(text):\n",
        "    \"\"\"\n",
        "    Process a text by converting it to lowercase, removing extra spaces and removing punctuations\n",
        "\n",
        "    Input:\n",
        "        - text: string\n",
        "    Output:\n",
        "        - string\n",
        "\n",
        "    \"\"\"\n",
        "    processed_text = None\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1ba0e3615fe4c91b7958db090781607b",
          "grade": true,
          "grade_id": "cell-0d71367e7eadb2e5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "yxxDc_0qi55w"
      },
      "outputs": [],
      "source": [
        "def test_text_processing():\n",
        "    assert text_processing(\"  This is a    string   \") == \"this is a string\"\n",
        "    assert text_processing(\"Hello! How are you?\") == \"hello how are you\"\n",
        "    assert text_processing(\"  This is a    string   with punctuations! \") == \"this is a string with punctuations\"\n",
        "    print(\"All tests pass\")\n",
        "\n",
        "test_text_processing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "64dce26e5449aea4c0098a8c5d45038b",
          "grade": false,
          "grade_id": "cell-b93a88faac1d07f0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JdTOkGMwi55w"
      },
      "source": [
        "### Containers\n",
        "\n",
        "Python includes several built-in container types: lists, dictionaries, sets, and tuples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5e9207b88380753feceb5fb9e07d208a",
          "grade": false,
          "grade_id": "cell-2bca4ba13a63ef9a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2Bvnr824i55x"
      },
      "source": [
        "#### Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "13ab38d5e3a7f751a638a08c46f45a8e",
          "grade": false,
          "grade_id": "cell-60bd176bcf23fe39",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zQyP-SyDi55x"
      },
      "source": [
        "A list is the Python equivalent of an array, but is resizeable and can contain elements of different types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ0rSfjqi55x"
      },
      "outputs": [],
      "source": [
        "xs = [3, 1, 2]  # Create a list\n",
        "print(xs, xs[2])\n",
        "print(xs[-1])  # Negative indices count from the end of the list; prints \"2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0fRNxqPi55x"
      },
      "outputs": [],
      "source": [
        "xs[2] = \"foo\"  # Lists can contain elements of different types\n",
        "print(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eti_l5D8i55x"
      },
      "outputs": [],
      "source": [
        "xs.append(\"bar\")  # Add a new element to the end of the list\n",
        "print(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsGhCWdgi55x"
      },
      "outputs": [],
      "source": [
        "x = xs.pop()  # Remove and return the last element of the list\n",
        "print(x, xs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d7718e3a47326103ebf692baa71d3bc9",
          "grade": false,
          "grade_id": "cell-a015128a3fa0ed8d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HCEs_s1Ui55x"
      },
      "source": [
        "As usual, you can find all the gory details about lists in the [documentation](https://docs.python.org/3.7/tutorial/datastructures.html#more-on-lists)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a6b9435a67e2a19fa5edeae95bca5725",
          "grade": false,
          "grade_id": "cell-547b907038385349",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ddYT7VKfi55x"
      },
      "source": [
        "#### Slicing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e4020808791bd78ab1071d272e6eba64",
          "grade": false,
          "grade_id": "cell-ee5148a00c4417ab",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oDnfAeTPi55x"
      },
      "source": [
        "In addition to accessing list elements one at a time, Python provides concise syntax to access sublists; this is known as slicing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm-LY14qi55x"
      },
      "outputs": [],
      "source": [
        "nums = list(range(5))  # range is a built-in function that creates a list of integers\n",
        "print(nums)  # Prints \"[0, 1, 2, 3, 4]\"\n",
        "print(nums[2:4])  # Get a slice from index 2 to 4 (exclusive); prints \"[2, 3]\"\n",
        "print(nums[2:])  # Get a slice from index 2 to the end; prints \"[2, 3, 4]\"\n",
        "print(nums[:2])  # Get a slice from the start to index 2 (exclusive); prints \"[0, 1]\"\n",
        "print(nums[:])  # Get a slice of the whole list; prints [\"0, 1, 2, 3, 4]\"\n",
        "print(nums[:-1])  # Slice indices can be negative; prints [\"0, 1, 2, 3]\"\n",
        "nums[2:4] = [8, 9]  # Assign a new sublist to a slice\n",
        "print(nums)  # Prints \"[0, 1, 8, 9, 4]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "499878e9df18b7c1631ce18acc46fb53",
          "grade": false,
          "grade_id": "cell-d4a7dc32bbed9c9d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eKC_GtuWi55y"
      },
      "source": [
        "#### Loops\n",
        "\n",
        "You can loop over the elements of a list like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkmSRAShi55y"
      },
      "outputs": [],
      "source": [
        "animals = [\"cat\", \"dog\", \"monkey\"]\n",
        "for animal in animals:\n",
        "    print(animal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXT-lo7Ei55y"
      },
      "source": [
        "If you want access to the index of each element within the body of a loop, use the built-in `enumerate` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SYHtRGWi55y"
      },
      "outputs": [],
      "source": [
        "animals = [\"cat\", \"dog\", \"monkey\"]\n",
        "for idx, animal in enumerate(animals):\n",
        "    print(f\"#{idx+1}: {animal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86c6f7fe13cbd23235589198cc5dd60c",
          "grade": false,
          "grade_id": "cell-7e5ba131ac9b3c1d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UaKjxOXii55y"
      },
      "source": [
        "#### List comprehensions:\n",
        "When programming, frequently we want to transform one type of data into another. As a simple example, consider the following code that computes square numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGLm0b7ii55y"
      },
      "outputs": [],
      "source": [
        "nums = [0, 1, 2, 3, 4]\n",
        "squares = []\n",
        "for x in nums:\n",
        "    squares.append(x**2)\n",
        "print(squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KagoDajFi55y"
      },
      "source": [
        "You can make this code simpler using a list comprehension:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LQ-H_HWi55y"
      },
      "outputs": [],
      "source": [
        "nums = [0, 1, 2, 3, 4]\n",
        "squares = [x**2 for x in nums]\n",
        "print(squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-5nENHai55y"
      },
      "source": [
        "List comprehensions can also contain conditions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5K0aVqvi55y"
      },
      "outputs": [],
      "source": [
        "nums = [0, 1, 2, 3, 4]\n",
        "even_squares = [x**2 for x in nums if x % 2 == 0]\n",
        "print(even_squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b7e7b9942d9dd7e2f925e4a50ca4acf5",
          "grade": false,
          "grade_id": "cell-42411258549847e8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3idoHhIgi55y"
      },
      "source": [
        "#### Dictionaries\n",
        "\n",
        "A dictionary stores (key, value) pairs, similar to a `Map` in Java or an object in Javascript. You can use it like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU2iscaki55y"
      },
      "outputs": [],
      "source": [
        "d = {\"cat\": \"cute\", \"dog\": \"furry\"}  # Create a new dictionary with some data\n",
        "print(d[\"cat\"])  # Get an entry from a dictionary; prints \"cute\"\n",
        "print(\"cat\" in d)  # Check if a dictionary has a given key; prints \"True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeeBesKyi55y"
      },
      "outputs": [],
      "source": [
        "d[\"fish\"] = \"wet\"  # Set an entry in a dictionary\n",
        "print(d[\"fish\"])  # Prints \"wet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Yv8vBci55z"
      },
      "outputs": [],
      "source": [
        "print(d[\"monkey\"])  # KeyError: 'monkey' not a key of d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXP9VI6Bi55z"
      },
      "outputs": [],
      "source": [
        "print(d.get(\"monkey\", \"N/A\"))  # Get an element with a default; prints \"N/A\"\n",
        "print(d.get(\"fish\", \"N/A\"))  # Get an element with a default; prints \"wet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2hSWESzi55z"
      },
      "outputs": [],
      "source": [
        "del d[\"fish\"]  # Remove an element from a dictionary\n",
        "print(d.get(\"fish\", \"N/A\"))  # \"fish\" is no longer a key; prints \"N/A\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTsKxYHci55z"
      },
      "source": [
        "You can find all you need to know about dictionaries in the [documentation](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erV-niAWi55z"
      },
      "source": [
        "It is easy to iterate over the keys in a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUfO2rcoi55z"
      },
      "outputs": [],
      "source": [
        "d = {\"person\": 2, \"cat\": 4, \"spider\": 8}\n",
        "for animal, legs in d.items():\n",
        "    print(f\"A {animal} has {legs} legs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03U3MXNUi55z"
      },
      "source": [
        "Dictionary comprehensions: These are similar to list comprehensions, but allow you to easily construct dictionaries. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpF7PPtFi55z"
      },
      "outputs": [],
      "source": [
        "nums = [0, 1, 2, 3, 4]\n",
        "even_num_to_square = {x: x**2 for x in nums if x % 2 == 0}\n",
        "print(even_num_to_square)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt5ccM7Pi55z"
      },
      "source": [
        "#### Sets\n",
        "A set is an unordered collection of distinct elements. As a simple example, consider the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsNwDwdni55z"
      },
      "outputs": [],
      "source": [
        "animals = {\"cat\", \"dog\"}\n",
        "print(\"cat\" in animals)  # Check if an element is in a set; prints \"True\"\n",
        "print(\"fish\" in animals)  # prints \"False\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FxFEYK3i55z"
      },
      "outputs": [],
      "source": [
        "animals.add(\"fish\")  # Add an element to a set\n",
        "print(\"fish\" in animals)\n",
        "print(len(animals))  # Number of elements in a set;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah5yEbtyi55z"
      },
      "outputs": [],
      "source": [
        "animals.add(\"cat\")  # Adding an element that is already in the set does nothing\n",
        "print(len(animals))\n",
        "animals.remove(\"cat\")  # Remove an element from a set\n",
        "print(len(animals))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnNnKntpi55z"
      },
      "source": [
        "_Loops_: Iterating over a set has the same syntax as iterating over a list; however since sets are unordered, you cannot make assumptions about the order in which you visit the elements of the set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNGZvdkmi55z"
      },
      "outputs": [],
      "source": [
        "animals = {\"cat\", \"dog\", \"fish\"}\n",
        "for idx, animal in enumerate(animals):\n",
        "    print(f\"#{idx + 1}: {animal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF9DMuhVi55z"
      },
      "source": [
        "Set comprehensions: Like lists and dictionaries, we can easily construct sets using set comprehensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsCmLZsni55z"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "print({int(sqrt(x)) for x in range(30)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CldD2T0Ji550"
      },
      "source": [
        "#### Tuples\n",
        "\n",
        "A tuple is an (immutable) ordered list of values. A tuple is in many ways similar to a list; one of the most important differences is that tuples can be used as keys in dictionaries and as elements of sets, while lists cannot. Here is a trivial example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MXPTp-oi550"
      },
      "outputs": [],
      "source": [
        "d = {(x, x + 1): x for x in range(10)}  # Create a dictionary with tuple keys\n",
        "t = (5, 6)  # Create a tuple\n",
        "print(type(t))\n",
        "print(d[t])\n",
        "print(d[(1, 2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6FyoRq0i550"
      },
      "outputs": [],
      "source": [
        "t[0] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5d046b0ecd34a89d335b5fa58bb6c3f7",
          "grade": false,
          "grade_id": "cell-c3eb7edad36dfe60",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "i9Am_wSri550"
      },
      "source": [
        "### Exercise 2: Word Tokenization and Converting Tokens to IDs (Level 2)\n",
        "\n",
        "When working with text data most Machine Learning / Deep Learning algorithms treat text as a sequence of smaller units, which are also called tokens. While there exists different levels of granularities on what constitutes as a token, for this notebook we will focus on the classical approach of word tokenization i.e. the text is split into a sequence of words.\n",
        "\n",
        "E.g. ``` \"This is a sentence about to be word tokenized\" -> [\"This\", \"is\", \"a\", \"sentence\", \"about\", \"to\", \"be\", \"word\", \"tokenized\"]```\n",
        "\n",
        "Tokenization is usually followed by a step converting the tokens into a set of input ids. As you will learn during the course, machines do not have semantic knowledge of words built in, and learning algorithms treat these words as numbers identifying (IDs) each word or token. These IDs are typically assigned according to the index of a word in the vocabulary, which is a list of all unique words in the training corpus.\n",
        "\n",
        "E.g. For a vocabulary: ```vocab = [\"A\", a\", \"cat\", \"mat\", \"on\", \"sits\"]```, the sentence ```\"a cat sits on a mat\"``` with tokens ```[\"A\", \"cat\", \"sits\", \"on\", \"a\", \"mat\"]```, will get converted to the list of ids: ```[0, 2, 5, 4, 1, 3]```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c440bdebb4ccc25aa403ca183cdded9b",
          "grade": false,
          "grade_id": "cell-ec56531958f040d0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ePMCTLlSi550"
      },
      "source": [
        "Below you will implement the necessary functionality to implement word tokenization and conversion of words into ids. Specifically you will implement three functions:\n",
        "\n",
        "- `word_tokenize` : Converts a text (represented as python string) into a sequence of words\n",
        "- `fit_vocab`: Constructs vocabulary i.e. list of unique tokens from a corpus (a list of text documents)\n",
        "- `convert_token_to_ids`: Converts a list of tokens to ids\n",
        "\n",
        "You will be using functionalities from different containers like lists, sets, and dictionaries, which you just learned. Like previous exercise, we recommend you to avoid using any external libraries to do this exercise to maximize your learning of the underlying concepts.\n",
        "\n",
        "**Important Note: Remove `raise NotImplementedError()` when you write your code in the functions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "47f2ab26e9829bfe2742a139abf9fc36",
          "grade": false,
          "grade_id": "cell-14520531a5c2169c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Y0sj_kdNi550"
      },
      "outputs": [],
      "source": [
        "def word_tokenize(text: str) -> list:\n",
        "    \"\"\"\n",
        "    Tokenize a text into words. You can assume that no punctuations are present in the text.\n",
        "\n",
        "    E.g.: \"we all live in a yellow submarine\" -> [\"we\", \"all\", \"live\", \"in\", \"a\", \"yellow\", \"submarine\"]\n",
        "\n",
        "    Input:\n",
        "        - text: string\n",
        "    Output:\n",
        "        - list of strings\n",
        "\n",
        "    \"\"\"\n",
        "    words = None\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6a0c92bb70c6c6f9ec4963ae4c9ac84",
          "grade": true,
          "grade_id": "cell-da4dc5898efa830f",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fJi1LvSXi550"
      },
      "outputs": [],
      "source": [
        "def test_word_tokenize():\n",
        "    assert word_tokenize(\"we all live in a yellow submarine\") == [\n",
        "        \"we\",\n",
        "        \"all\",\n",
        "        \"live\",\n",
        "        \"in\",\n",
        "        \"a\",\n",
        "        \"yellow\",\n",
        "        \"submarine\",\n",
        "    ]\n",
        "    assert word_tokenize(\"This is a sentence about to be word tokenized?\") == [\n",
        "        \"This\",\n",
        "        \"is\",\n",
        "        \"a\",\n",
        "        \"sentence\",\n",
        "        \"about\",\n",
        "        \"to\",\n",
        "        \"be\",\n",
        "        \"word\",\n",
        "        \"tokenized?\",\n",
        "    ]\n",
        "    print(\"All tests pass\")\n",
        "\n",
        "\n",
        "test_word_tokenize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3e30e605d8264621d5e84c0e3568f13a",
          "grade": false,
          "grade_id": "cell-e2f0d372919b87c4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "544Y3aXBi550"
      },
      "outputs": [],
      "source": [
        "def fit_vocab(corpus):\n",
        "    \"\"\"\n",
        "    Creates a vocabulary from a corpus i.e. a list of documents.\n",
        "\n",
        "\n",
        "    Input:\n",
        "        - corpus: list of strings\n",
        "    Output:\n",
        "        - List of unique words in the corpus (sorted in alphabetical order)\n",
        "        - Dictionary mapping each word to its index in the vocabulary\n",
        "\n",
        "    Important: Remember to sort the vocabulary before using it to construct the dictionary mapping\n",
        "    \"\"\"\n",
        "\n",
        "    vocab = None\n",
        "    word_to_idx = None\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return vocab, word_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe6cf792e05ad9dd838ff2362e22dc2f",
          "grade": true,
          "grade_id": "cell-da20f6bfa22f808b",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eAm9h2Aai550"
      },
      "outputs": [],
      "source": [
        "def test_fit_vocab():\n",
        "    corpus = [\n",
        "        \"We all live in a yellow submarine\",\n",
        "        \"I am the walrus\",\n",
        "        \"Yellow Submarine\",\n",
        "    ]\n",
        "    vocab, word_to_idx = fit_vocab(corpus)\n",
        "    assert vocab == [\n",
        "        \"I\",\n",
        "        \"Submarine\",\n",
        "        \"We\",\n",
        "        \"Yellow\",\n",
        "        \"a\",\n",
        "        \"all\",\n",
        "        \"am\",\n",
        "        \"in\",\n",
        "        \"live\",\n",
        "        \"submarine\",\n",
        "        \"the\",\n",
        "        \"walrus\",\n",
        "        \"yellow\",\n",
        "    ]\n",
        "    assert word_to_idx == {\n",
        "        \"I\": 0,\n",
        "        \"Submarine\": 1,\n",
        "        \"We\": 2,\n",
        "        \"Yellow\": 3,\n",
        "        \"a\": 4,\n",
        "        \"all\": 5,\n",
        "        \"am\": 6,\n",
        "        \"in\": 7,\n",
        "        \"live\": 8,\n",
        "        \"submarine\": 9,\n",
        "        \"the\": 10,\n",
        "        \"walrus\": 11,\n",
        "        \"yellow\": 12,\n",
        "    }\n",
        "\n",
        "    print(\"All tests pass\")\n",
        "\n",
        "\n",
        "test_fit_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e2883635483850bd5ba6f4648b81ad20",
          "grade": false,
          "grade_id": "cell-437d01662d031940",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IoXP_Rrti550"
      },
      "outputs": [],
      "source": [
        "def convert_tokens_to_ids(tokens, word_to_idx):\n",
        "    \"\"\"\n",
        "    Convert a list of tokens to a list of token ids using the word_to_idx dictionary.\n",
        "\n",
        "    Input:\n",
        "        - tokens: list of strings\n",
        "        - word_to_idx: dictionary mapping words to their ids\n",
        "    Output:\n",
        "        - list of integers\n",
        "    \"\"\"\n",
        "\n",
        "    token_ids = None\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    return token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5632641c6ad0cb0532362dbec0d42d",
          "grade": true,
          "grade_id": "cell-1c0ee37757d295c9",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "daCBM0HDi550"
      },
      "outputs": [],
      "source": [
        "def test_convert_tokens_to_ids():\n",
        "    word_to_idx = {\n",
        "        \"I\": 0,\n",
        "        \"Submarine\": 1,\n",
        "        \"We\": 2,\n",
        "        \"Yellow\": 3,\n",
        "        \"a\": 4,\n",
        "        \"all\": 5,\n",
        "        \"am\": 6,\n",
        "        \"in\": 7,\n",
        "        \"live\": 8,\n",
        "        \"submarine\": 9,\n",
        "        \"the\": 10,\n",
        "        \"walrus\": 11,\n",
        "        \"yellow\": 12,\n",
        "    }\n",
        "    tokens = [\"We\", \"all\", \"live\", \"in\", \"a\", \"yellow\", \"submarine\"]\n",
        "    assert convert_tokens_to_ids(tokens, word_to_idx) == [2, 5, 8, 7, 4, 12, 9]\n",
        "    print(\"All tests pass\")\n",
        "\n",
        "\n",
        "test_convert_tokens_to_ids()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a3e392b584141681e60c3e69675dad76",
          "grade": false,
          "grade_id": "cell-2a56324d8ad9e739",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "egOE3vSUi550"
      },
      "source": [
        "### Classes\n",
        "\n",
        "The syntax for defining classes in Python is straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPyMERwBi551"
      },
      "outputs": [],
      "source": [
        "class Greeter:\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, name):\n",
        "        self.name = name  # Create an instance variable\n",
        "\n",
        "    # Instance method\n",
        "    def greet(self, loud=False):\n",
        "        if loud:\n",
        "            print(\"HELLO, {}\".format(self.name.upper()))\n",
        "        else:\n",
        "            print(\"Hello, {}!\".format(self.name))\n",
        "\n",
        "\n",
        "g = Greeter(\"Fred\")  # Construct an instance of the Greeter class\n",
        "g.greet()  # Call an instance method; prints \"Hello, Fred\"\n",
        "g.greet(loud=True)  # Call an instance method; prints \"HELLO, FRED!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3089c5a4eab41b4467128cf5f1c086bf",
          "grade": false,
          "grade_id": "cell-b61193214c639611",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rZXEXAl5i551"
      },
      "source": [
        "### Exercise 3: Implementing the Full Tokenization Pipeline from Scratch (Level 3)\n",
        "\n",
        "We will now take everything we learned to implement a typical tokenization pipeline very similar to the one used in [Hugging Face Transformers library](https://huggingface.co/docs/tokenizers/en/pipeline). In particular, you will implement the class `WordTokenizer` with the following methods:\n",
        "\n",
        "- `normalizer`: Applies the text processing techniques to the input text (we will use the same 3 techniques we implemented before; we use a different terminology i.e. normalizer instead of processing to be close to the huggingface naming convention)\n",
        "- `tokenize`: Splits the text into a list of words\n",
        "- `convert_tokens_to_ids`: Converts a list of tokens to a list of ids\n",
        "- `convert_ids_to_tokens`: Converts a list of ids to a list of tokens\n",
        "- `encode`: Applies `tokenize` and `convert_tokens_to_ids` methods in succession to an input text\n",
        "- `decode`: Converts the list of ids back to the text form\n",
        "- `train`: Trains the tokenizer, which for the word tokenizer means simply fitting the vocabulary over the corpus\n",
        "  \n",
        "**Important Note: Remove `raise NotImplementedError()` when you write your code in the functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eee7f6e00c30d4da389669e694b37a41",
          "grade": false,
          "grade_id": "cell-66b4de2616f3e708",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "yftk6uqCi551"
      },
      "outputs": [],
      "source": [
        "class WordTokenizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Constructor for the WordTokenizer class.\n",
        "\n",
        "        Initialize `vocab` attribute as an empty list and `word_to_idx` attribute as an empty dictionary.\n",
        "        \"\"\"\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def normalizer(self, text):\n",
        "        \"\"\"\n",
        "        Normalizes the input text by converting it to lowercase, removing extra spaces, and removing punctuations.\n",
        "\n",
        "        Input:\n",
        "            - text: string\n",
        "        Output:\n",
        "            - string\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        normalized_text = None\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        return normalized_text\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"\n",
        "        Tokenizes the input text into words.\n",
        "\n",
        "        Input:\n",
        "            - text: string\n",
        "        Output:\n",
        "            - list of strings\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        tokens = None\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        return tokens\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        \"\"\"\n",
        "        Convert a list of tokens to a list of token ids using the word_to_idx dictionary.\n",
        "\n",
        "        Input:\n",
        "            - tokens: list of strings\n",
        "        Output:\n",
        "            - list of integers\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Throw an error if the word_to_idx dictionary is empty\n",
        "        if not self.word_to_idx:\n",
        "            raise ValueError(\"Tokenizer has not been fit on a vocabulary yet. Call `train` method with a corpus first!\")\n",
        "\n",
        "        token_ids = None\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        return token_ids\n",
        "\n",
        "    def convert_ids_to_tokens(self, token_ids):\n",
        "        \"\"\"\n",
        "        Convert a list of token ids to a list of tokens using the idx_to_word dictionary.\n",
        "\n",
        "        Input:\n",
        "            - token_ids: list of integers\n",
        "        Output:\n",
        "            - list of strings\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Throw an error if the vocabulary is empty\n",
        "        if self.vocab == []:\n",
        "            raise ValueError(\"Tokenizer has not been fit on a vocabulary yet. Call `train` method with a corpus first!\")\n",
        "\n",
        "        tokens = None\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"\n",
        "        Encodes the input text into token ids. Do not forget to normalize the text before tokenizing it.\n",
        "\n",
        "        Input:\n",
        "            - text: string\n",
        "        Output:\n",
        "            - list of integers\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        token_ids = None\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        return token_ids\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        \"\"\"\n",
        "        Decodes the input token ids into text.\n",
        "\n",
        "        Input:\n",
        "            - token_ids: list of integers\n",
        "        Output:\n",
        "            - string\n",
        "\n",
        "        \"\"\"\n",
        "        text = None\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        return text\n",
        "\n",
        "    def train(self, corpus):\n",
        "        \"\"\"\n",
        "        Trains the tokenizer on a corpus i.e. a list of documents, filling in values of `self.vocab` and `self.word_to_idx`.\n",
        "\n",
        "        Input:\n",
        "            - corpus: list of strings\n",
        "\n",
        "        Note: Do not forget to normalize the text before tokenizing it.\n",
        "        \"\"\"\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b68f4d1c7662cf791ab02f75e1388c62",
          "grade": true,
          "grade_id": "cell-65defcf000eeba30",
          "locked": true,
          "points": 1.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "r103d7J-i551"
      },
      "outputs": [],
      "source": [
        "def test_WordTokenizer():\n",
        "    tokenizer = WordTokenizer()\n",
        "    corpus = [\n",
        "        \"We all live in a yellow submarine\",\n",
        "        \"I am the walrus\",\n",
        "        \"Yellow Submarine\",\n",
        "    ]\n",
        "    tokenizer.train(corpus)\n",
        "    token_ids = tokenizer.encode(\"We all live in a yellow submarine\")\n",
        "\n",
        "    assert token_ids == [9, 1, 5, 4, 0, 10, 6]\n",
        "\n",
        "    text = tokenizer.decode(token_ids)\n",
        "    assert text == \"we all live in a yellow submarine\"\n",
        "\n",
        "    print(\"All tests pass\")\n",
        "\n",
        "\n",
        "test_WordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1RB6wHn3Nzpi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Pbig2pBmi55s",
        "XuFsfyDfi55u",
        "-zlXbhgKi55v",
        "bzsBLjZwi55v",
        "Yp-3YIt9i55w",
        "guryGLbzi55w",
        "JdTOkGMwi55w",
        "i9Am_wSri550",
        "egOE3vSUi550",
        "rZXEXAl5i551"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}